
---

title: Exposing a MCP Server to OpenAI
description: Connect ChatGPT with your local MCP server
---

import { Image } from 'astro:assets';

import inspectrExpose from '../../../../assets/guides/mcp-openai-inspectr-expose2.png';
import mcpChatGptResultGraph from '../../../../assets/guides/mcp-openai-connector-result-graph.png';
import mcpChatGptResult from '../../../../assets/guides/mcp-openai-connector-result.png';
import mcpOpenAIConnectorUse from '../../../../assets/guides/mcp-openai-connector-use.png';
import mcpOpenAIConnectorNew from '../../../../assets/guides/mcp-openai-connector-new.png';
import mcpOpenAIConnector from '../../../../assets/guides/mcp-openai-connector.png';
import mcpOpenAIConnectorConnected from '../../../../assets/guides/mcp-openai-connector-connected.png';
import mcpOpenAIDevMode from '../../../../assets/guides/mcp-openai-dev-mode.png';
//import mcpInspectrRequest from '../../../../assets/guides/mcp-openai-inspectr-request.png';
import mcpInspectrRequest from '../../../../assets/features/mcp/mcp-request.png';
import mcpInspectrToolList from '../../../../assets/features/mcp/mcp-tool-list-openai.png';
//import mcpInspectrResponse from '../../../../assets/guides/mcp-openai-inspectr-response.png';
import mcpInspectrResponse from '../../../../assets/features/mcp/mcp-tool-fetch.png';
import mcpOpenAI from '../../../../assets/guides/mcp-openai.png';
import mcpOpenAICreate from '../../../../assets/guides/mcp-openai-create.png';

import { FlowBase, FlowIngress } from '../../../../components/DocFlows/FlowMcpOpenAI.jsx';
import RelatedLink from '../../../../components/RelatedLink.jsx';

[//]: # (## Expose your Local MCP in One Command)

Ever tried testing and debugging a local MCP server in ChatGPT or Claude?
It’s tricky to connect the LLM with your local MCP server.

With Inspectr, you can expose your local MCP with one simple command:

```bash
inspectr --backend=http://localhost:3000 --expose
```

Your local MCP server is now publicly available and ready to connect with ChatGPT.
And as an extra handy bonus, you can see exactly how the LLM interacts with it in the Inspectr App.

<FlowIngress client:only="react" />

---

## Unlock MCP in ChatGPT with Inspectr

Since the summer of 2025, you can enable ["Custom Connectors"](https://help.openai.com/en/articles/6825453-chatgpt-release-notes#h_9fb0469813) in Developer Mode in ChatGPT to use remote **MCP Servers**!

With the [MCP (Model Context Protocol)](https://platform.openai.com/docs/mcp#create-an-mcp-server), you can connect proprietary systems and apps to OpenAI, allowing you to search, reason, and act with any local MCP server in ChatGPT, right alongside web results and built-in connectors.

Inspectr makes it simple to expose your MCP server securely and inspect how ChatGPT uses your MCP tools, prompts, and resources.

---

### What You’ll Learn

* Enable Developer Mode in ChatGPT
* Expose your local MCP server using Inspectr
* Connect it to ChatGPT as a "custom connector"
* Use your MCP server directly in ChatGPT conversations
* Inspect requests and responses in the Inspectr UI

---

#### Prerequisites

* A running MCP-compatible server [(more info in the OpenAI MCP docs)](https://platform.openai.com/docs/mcp#create-an-mcp-server)
* Inspectr installed ([Install Guide →](/docs/getting-started/installation/))

---

## Step 1: Start Your MCP Server

Make sure your MCP server is running locally, using the "streamable http" as transport. For this example we run it on port `3000`.

[//]: # (For this example, we'll use the [MCP Server]&#40;https://github.com/inspectr/mcp-server&#41; from Inspectr.)

```bash
mcp-server --port 3000
```

---

## Step 2: Expose MCP via Inspectr

Run Inspectr with the `--expose` flag:

```bash
inspectr \
  --backend=http://localhost:3000 \
  --expose \
  --channel=mcp-demo \
  --channel-code=mcpserver123
```

<Image src={inspectrExpose} alt="Inspectr exposing MCP server" />

Your MCP server is now available at:

```
https://mcp-demo.in-spectr.dev/mcp
```

* Inspectr listens on port `8080` (use `--listen=` to change this)
* Forwards traffic to your MCP server on port `3000`
* Captures and displays traffic in the App UI at [http://localhost:4004](http://localhost:4004)

---

## Step 3: Enable Developer Mode in ChatGPT

Go to "Settings" → "Connectors" → "Advanced settings"

<Image src={mcpOpenAI} alt="ChatGPT connector settings" />

and enable **Developer Mode**.

<Image src={mcpOpenAIDevMode} alt="Enable Developer Mode in ChatGPT" />

---

## Step 4: Add a Custom Connector

In ChatGPT, go to "Settings" → "Connectors"

<Image src={mcpOpenAICreate} alt="Create new connector" />

After enabling **Developer Mode**, click "Create" to add a new connector.

<Image src={mcpOpenAIConnectorNew} alt="Add new MCP connector" />

Fill in the connector details, for example:

- **Name**: Inspectr
- **Description**: Inspectr MCP Server
- **MCP Server URL**: `https://mcp-demo.in-spectr.dev/mcp`
- **Authentication**: "No authentication" (or set to the method your MCP server requires)
- Tick "I trust this application"

<Image src={mcpOpenAIConnector} alt="Connector details entered" />

Press "Create" to save the connector. ChatGPT will then attempt to connect to your MCP server.

Once connected, you should see connection details and a list of available actions.

<Image src={mcpOpenAIConnectorConnected} alt="Connector connected view" />

---

## Step 5: Use Inspectr in ChatGPT

Once connected, you can select the connector, and the MCP server will appear under "Use tools" in the composer.

<Image src={mcpOpenAIConnectorUse} alt="Inspectr available as a tool" />

You can now run prompts that leverage the tools inside the MCP server and see the results directly in the chat.

For example, let's run a prompt that searches for the most used API endpoints:

<Image src={mcpChatGptResult} alt="Most used API endpoints result" />

Next we want see how the response times behaves:

<Image src={mcpChatGptResultGraph} alt="Response times over time graph" />

---

## View MCP Requests in Inspectr

To view how ChatGPT interacts with your MCP server; including tools, prompts, and resources — go to [http://localhost:4004](http://localhost:4004), where you’ll find a history of requests and responses.

_Request made by ChatGPT_
<Image src={mcpInspectrRequest} alt="Inspectr MCP request view" />

_Responses from the MCP server_

<Image src={mcpInspectrResponse} alt="Inspectr MCP insights view" />

<Image src={mcpInspectrToolList} alt="Inspectr MCP Tools view" />

---

## Summary

Inspectr makes it easy to:

- Expose your local MCP server to OpenAI ChatGPT
- Monitor and review how ChatGPT uses your MCP tools, prompts, and resources

<RelatedLink href="/mcp-insights/" title="Want to learn more about MCP insights? See our product page:">
  MCP Insights →
</RelatedLink>
